---
pageTitle: High availability
keywords: typedb, ha, replication, failover, raft
longTailKeywords: TypeDB replication, TypeDB high availability, high availability
summary: TypeDB high availability guarantees and solution.
toc: false
---

# High availability

## Overview

<div class="note">
[Note]
High availability features are available only in TypeDB Cloud.
</div>

TypeDB Cloud supports the following high availability features: 

* Server clusterization,
* [Strongly consistent model](https://en.wikipedia.org/wiki/Strong_consistency),
* Data and schema replication with primary/secondary replicas,
* Primary replica failover using [Raft consensus algorithm](https://en.wikipedia.org/wiki/Raft_(algorithm)),
* Synchronous replication using [Raft consensus algorithm](https://en.wikipedia.org/wiki/Raft_(algorithm)),
* Client level load balancing.

## Replication

TypeDB replication is performed at the database level. Specifically, there is a separate replication group for each 
database. Every database has a separate replication group. There can be multiple replicas of a database, but only one 
per server.

There are two types of replicas: primary replica and secondary ones (or leader and followers in Raft terms). There can 
be only one primary replica of a database at any given time. It is possible that primary replicas of different 
databases can be on the same or different servers. Primary replicas location can’t be set manually, only through
[election process](#leader-election) (as per Raft algorithm).

By default, all write and read operations are performed on the primary replica. Reads from secondary replicas have 
no guarantee of up-to-date data. But reads can be very costly (especially with rules). There is a "**read any replica**"
transaction option to be able to read data not only from primary replica. If the option set to **True** then TypeDB 
Client will choose a random replica to balance the load between replicas. 

<div class="note">
[Note]
TypeDB Cloud uses ZeroMQ for replication and gRPC for replication management.
</div>

### Leader election

All replicas start as secondary replica. The only way for replica to become a primary is to win an election. Election 
is won by a replica which is voted by the majority of replicas in cluster.

Any secondary that didn't hear from a primary for a set time out period plus/minus random margin will start an 
election. Every replica will participate in only one election at the same time.

For more information on Raft consensus algorithm please read the [Raft algorithm documentation](https://raft.github.io/).

### Synchronous replication

To support synchronous replication TypeDB Cloud sends transaction acknowledgement to a client only when consensus is 
reached — when the majority of replicas acknowledge receiving the replicated data.

## Data persistence

To persist data on disk TypeDB uses [RocksDB](https://rocksdb.org/) with its write-ahead-log (WAL). The data stored as 
files on filesystem in data directory set in the configuration file (it may be overridden by the command line 
arguments). WAL can be used to restore data that didn't get to main storage of a server due to sudden crash or a 
power loss.

There is also a raft replication log being used entirely for replication purposes.

## Load balancing

Load balancing can be done by TypeDB Client for read type transactions with the `read_any_replica` options set to 
`True`.

When instantiated, client usually set up with a list of all replica addresses. Additionally, it can use auto-discovery 
function to discover missing replicas. It’s done by obtaining list of known servers in the cluster from a server TypeDB 
Client was able to connect to.
